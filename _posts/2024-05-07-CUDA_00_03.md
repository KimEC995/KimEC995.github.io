---
title: CUDA 프로그램의 구조와 흐름
author: Kimec995
date: 2024-05-07 19:00:00 +09:00
categories: [CUDA]
tags: [Jetson, Developer_Kit, CUDA]
pin: true
math: true
mermaid: true
image: 
  path: /assets/img/postimg/JetsonNano_Logo.png
  alt: CUDA 프로그램의 구조와 흐름
---
이전 문서: [CUDA란](https://kimec995.github.io/posts/CUDA_00_02/)

# 구조
![image.png](\assets\img\postimg\Jetson\CUDA_Concept_Exp_Img_05.png)


CUDA 프로그램은 Host 코드와 Device 코드로 나뉜다. 두  장치는 서로 독립되어 사용하는 메모리 영역도 다르다.

- **Host Code** 
	- CPU와 메인보드에 귀속된 DRAM(System Memory, Host Memory 라고도 부른다)
	- 거의 모든 데이터는 Host_Memory 에 저장되어있다.

- **Device Code** 
	- GPU와 그에 귀속된 메모리(Device Memory 라고도 부른다.)
	- 데이터를 사용하려면 DRAM에서 복사해와야한다.

이 두 코드의 구분이 아주 자주 나오니 잘 구분하자.

- **번외) 통합메모리(Unified Memory)**
	CUDA v6.0 이후 부터 Host Memory 와 Device Memory를 하나의 논리적 주소 공간으로 묶은 기술. 
	이를 이용하면 명시적인 메모리 복사 없이 CUDA 프로그램 작성이 가능하다.
	간단하거나 프로토 코드를 작성할 때 유용하나 큰 프로젝트에선 Host <-> Device 간 메모리 교환이 빈번하게 일어나 성능이 떨어진다.

## 흐름

### 1. Host -> Device 데이터 복사

![image.png](\assets\img\postimg\Jetson\CUDA_Concept_Exp_Img_04.png)

GPU 처리를 위해 가장 먼저 할 일은 Host -> Device 데이터 복사이다. 
왜냐하면 HDD, SSD, Net 등등 모든 데이터는 우선적으로 Host_Memory에 저장되는데 GPU에서는 바로 해당 메모리 단에 접근이 불가능하기 때문이다.

### 2. GPU 연산

![image.png](\assets\img\postimg\Jetson\CUDA_Concept_Exp_Img_06.png)

GPU 연산은 커널 호출을 통해 시작되며 모든 데이터는 Device_Memory에서 관리한다.

### 3. Device -> Host 데이터 복사

![image.png](\assets\img\postimg\Jetson\CUDA_Concept_Exp_Img_07.png)

GPU연산 수행 결과 데이터는 1의 반대로 Device 단에서 Host 단으로 복사된다.

## 컴파일
[NVCC Compile WorkFlow](https://kimec995.github.io/posts/NVCC_Compile_WorkFlow/) 참고